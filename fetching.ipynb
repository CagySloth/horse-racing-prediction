{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Consolidation Pipeline\n",
    "\n",
    "## Final Data Structure\n",
    "We are analyzing horse racing, in our case we want the final data to be every attempt of every horse in every race.\n",
    "Therefore we'll first fetch all the race results that took place in the last 15 years (11k). For each race, there will be 8-13 horses.\n",
    "Take their results, combine with that race's background information (what's the course like, wet or dry, length of race..)\n",
    "Finally for each data point we would also like to know the horse's stats. Therefore we'll have to crawl for the performance of the horse as well.\n",
    "Finally combining them all together into a super dataset\n",
    "\n",
    "### Define Length of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapers import fetch_races_from_days_ago\n",
    "\n",
    "\n",
    "# fetch all races for the last 15 years\n",
    "fetch_races_from_days_ago(15 * 365, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Horse data for every Horse that is mentioned in each race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from loaders.consolidate_horse import append_horses_info\n",
    "\n",
    "directory = \"results/\"\n",
    "output_file = f\"{directory}/horse_res_15.csv\"\n",
    "files = os.listdir(directory)\n",
    "\n",
    "existing_links = set()\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    output_df = pd.read_csv(output_file)\n",
    "    if len(output_df.columns) > 0:\n",
    "        existing_links = set(output_df.iloc[:, 0])\n",
    "\n",
    "def process_link(link):\n",
    "    if pd.notna(link):\n",
    "        if link not in existing_links:\n",
    "            print(f\"Appending link: {link} to {output_file}\")\n",
    "            append_horses_info(link, output_file)\n",
    "            return link\n",
    "        else:\n",
    "            print(f\"Link {link} already exists in {output_file}\")\n",
    "    else:\n",
    "        print(\"Empty link\")\n",
    "    return None\n",
    "\n",
    "# Collect all links to process\n",
    "links_to_process = []\n",
    "for file in files:\n",
    "    if file.endswith(\".csv\") and not file.endswith(\"_bg.csv\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if len(df.columns) >= 13:\n",
    "            links_to_process.extend(df.iloc[:, 12].dropna().unique())\n",
    "\n",
    "# Filter out existing links\n",
    "links_to_process = [link for link in links_to_process if link not in existing_links]\n",
    "\n",
    "# Use ThreadPoolExecutor for multithreading\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    futures = {executor.submit(process_link, link): link for link in links_to_process}\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            existing_links.add(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the background data to the race data\n",
    "in each race there are 8-13 horses, each of these horses in the end will be a training data point in our model construction process\n",
    "therefore each of the data point would contain the background information about the race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders.consolidate_race import append_race_res\n",
    "import os\n",
    "import fnmatch\n",
    "from tqdm import tqdm\n",
    "\n",
    "directory = \"results/\"\n",
    "all_files = os.listdir(directory)\n",
    "output_file = f\"{directory}final2.csv\"\n",
    "\n",
    "csv_files = [os.path.join(directory, f) for f in all_files \n",
    "             if fnmatch.fnmatch(f, 'res_*.csv') and not fnmatch.fnmatch(f, '*_bg.csv')]\n",
    "\n",
    "for file in tqdm(csv_files, desc=\"Processing files\"):\n",
    "    append_race_res(file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Horse Data with Race Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = \"results/\"\n",
    "race_data_file = f\"{directory}final2.csv\"\n",
    "horse_data_file = f\"{directory}horse_res.csv\"\n",
    "\n",
    "df1 = pd.read_csv(race_data_file)\n",
    "df2 = pd.read_csv(horse_data_file)\n",
    "\n",
    "df_merged = pd.merge(df1, df2, on='URL', how='left')\n",
    "\n",
    "df_merged.to_csv(\"final_horse.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
